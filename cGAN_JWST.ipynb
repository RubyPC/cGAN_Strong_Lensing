{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662afa64",
   "metadata": {},
   "source": [
    "# Predicting Wavebands with a cGAN\n",
    "One of the most exciting applications of deep learning is image-to-image translation which includes tasks such as image colourisation and super resolution. This task needed a lot of human input and hardcoding several years ago but, with the development of deep learning over recent years, the whole process can be done end-to-end with the power of machine learning. \n",
    "\n",
    "Here, we are focussed on predicting long wavelength, hereafter $LW$, JWST data *2.4-5.0µm* of simulated strong gravitational lenses given the short wavelength, $SW$, data *0.6-2.4µm* as input to the network. The network we use is a *conditional Generative Adversarial Network*, hereafter cGAN, and the architecture and methods closely follows that of  \n",
    "[_**Image-to-Image Translation with Conditional Adversarial Networks**_](https://arxiv.org/abs/1611.07004) which may also be known by *pix2pix* where a general solution to many image-to-image translation problems is proposed, one being image colourisation. Using the trained cGAN, we are then of interest in predicting $LW$ JWST data of the strong gravitational lenses given Euclid VIS and NISP instrument data as input. Euclid VIS and NISP have a pixel resolution of $0.1\"/pix$ and $0.3\"/pix$, respectively, compared to the pixel resolution of JWST NIRcam being $0.03\"/pix$. Thus, we expect a more resolved image of the gravitational lens as observed by JWST. If we see a different image of the lens as observed by JWST, then this image is different in an interesting way- maybe we are seeing more obscure arcs and rings or maybe not a lens at all. So, we propose that the cGAN can act as an anomaly detector.\n",
    "\n",
    "In this approach, two losses are used, namely an L1 loss, which makes this task a regression task, and an adversarial (GAN) loss, which helps to solve the problem in an unsupervised manner. \n",
    "\n",
    "### The World of GANs ###\n",
    "The architecture used in this problem is a conditional GAN which uses an extra loss function, the L1 loss. It is useful to understand the setup of a GAN.\n",
    "In a GAN, there is a Generator and a Discriminator network which work together to solve a problem. In this model, the Generator network takes a 3-channel input, composed of the stacked short waveband data, NIRcam *F115W, F150W and F200W* filters, and produces a 3-channel output, that of the long waveband filters, NIRcam *F277W, F356W* and *F444W*. The Discriminator network takes the generated long waveband data and decides whether it is real or fake. Naturally, the Discriminator needs to see real inputs - those that are not produced by the Generator, and should learn that they are real. \n",
    "\n",
    "The condition on this model is that both the Generator and Discriminator *see* the input.\n",
    "Let's take a further look into what the cGAN is doing. Consider _**x**_ to be the input to the network, _**z**_ as the input noise for the Generator, and _**y**_ the output we expect from the Generator. Let G and D denote the Generator and Discriminator networks, respectively. The loss of the cGAN can be described via:\n",
    "\\\n",
    "![cGAN-loss](images/cGAN-loss.png).\n",
    "\\\n",
    "Note that _**x**_ is the condition that we have introduced and it is seen by both networks. Also note that we are *not* feeding an *n*-dimensional vector of random noise to the Generator, which is common in machine learning networks, since the noise is introduced in the form of dropout layers in the Generator network.\n",
    "\n",
    "#### Loss Function ####\n",
    "The goal is optimisation and, more specifically, to minimise the loss. The above loss function helps to produce an output that seems real, however, to further steer the model in the right direction and to introduce some supervision into this task, we combine the above loss with the L1 loss (which can be also known as the mean absolute error):\n",
    "\\\n",
    "![L1 loss](images/L1-loss.png).\n",
    "\\\n",
    "The model will learn features from the data using the L1 loss alone, but it will be conservative and take an average which will reduce the L1 loss as much as possible (this can be compared to the blurring effect of L1 or L2 loss in a super resolution task). Combining the adversarial loss with the L1 loss gives the overall loss function for the model:\n",
    "\\\n",
    "![loss](images/Loss.png),\n",
    "\\\n",
    "where *λ* is the coefficient to balance the contribution of the two losses to the final loss. Note that the discriminator loss does not involve the L1 loss. \n",
    "\n",
    "### Implementing the cGAN ###\n",
    "The cGAN is implemented using Pytorch; a convenient package for machine learning models. This example uses ~ 1000 input data in the form of the simulated strong gravitational lenses of size $64\\times 64$ simulated using lenstronomy. The notebook for simulated strong gravitational lenses using lenstronomy is given in this repository. You are welcome to train the network on your own data provided it is in the same format. This is discussed in the README page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0ef476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "from astropy.io import fits\n",
    "import warnings\n",
    "import glob\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\\..*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dac9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to YOUR working directory\n",
    "home = \"/Users/ruby/Documents/Python Scripts/cGAN/Euclid-JWST/Data/Lens_Source/HighRes/\"\n",
    "\n",
    "# list of filters which is then split into SW filters and LW filters\n",
    "filters = ['F115W/', 'F150W/', 'F200W/', 'F277W/', 'F356W/', 'F444W/']\n",
    "# now the Euclid filters\n",
    "filters_Euclid = ['VIS', 'NISP-J', 'NISP-Y', 'NISP-H']\n",
    "nbands = len(filters)\n",
    "n_filters = len(filters_Euclid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79139d80",
   "metadata": {},
   "source": [
    "The data that we simulated in the previous notebooks must be processed before feeding to the network. Since large pixel values will cause long training times, we choose to normalise the data appropriately across all 6 wavebands. To do this, we plot a histogram of each data file we previously extracted for each waveband and take the lower and upper $10\\%$ percentiles.\n",
    "The Euclid data is normalised in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7c48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_Percentiles(path, filtername):\n",
    "    file_list = glob.glob(f\"{path}/{filtername}/*.fits\")\n",
    "    bins = np.linspace(1e-9, np.log10(5), 100)\n",
    "    hists = []\n",
    "    for i in file_list:\n",
    "        with fits.open(i) as fitsfile:\n",
    "            img = fitsfile[0].data #removed np.log10\n",
    "            hist, bins = np.histogram(img, bins=bins)\n",
    "            hists.append(hist)\n",
    "    hists_sum = np.sum(hists, axis=0)\n",
    "    total = hists_sum.sum()\n",
    "    lower = 0.\n",
    "    upper = 0.\n",
    "    for i in range(len(hists_sum)):\n",
    "        lower += hists_sum[i]\n",
    "        if lower > .1*total:\n",
    "            percentile_lower = bins[i]\n",
    "            break\n",
    "    for j in range(len(hists_sum)):\n",
    "        upper += hists_sum[-j]\n",
    "        if upper > 0.1*total:\n",
    "            percentile_upper = bins[-(j+1)]\n",
    "            break\n",
    "    return percentile_lower, percentile_upper, hists_sum\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a085fc0",
   "metadata": {},
   "source": [
    "Now, we create a list to append the percentiles of each waveband to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73682b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveband_percentiles = []\n",
    "for filter_ in filters:\n",
    "    lower, upper, sum1 = Filter_Percentiles(home, filter_)\n",
    "    waveband_percentiles.append([lower, upper])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e715e45",
   "metadata": {},
   "source": [
    "Since *waveband_percentiles* contains the information of the lower and upper extreme percentiles of the wavebands in the order $F115W...F444W$, we can set the lower and upper percentiles for each waveband individually to use for the normalisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d34822",
   "metadata": {},
   "outputs": [],
   "source": [
    "f115w_lower, f115w_upper = waveband_percentiles[0][0], waveband_percentiles[0][1] \n",
    "f150w_lower, f150w_upper = waveband_percentiles[1][0], waveband_percentiles[1][1] \n",
    "f200w_lower, f200w_upper = waveband_percentiles[2][0], waveband_percentiles[2][1] \n",
    "f277w_lower, f277w_upper = waveband_percentiles[3][0], waveband_percentiles[3][1] \n",
    "f356w_lower, f356w_upper = waveband_percentiles[4][0], waveband_percentiles[4][1] \n",
    "f444w_lower, f444w_upper = waveband_percentiles[5][0], waveband_percentiles[5][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe902215",
   "metadata": {},
   "source": [
    "Before we create our dataset and dataloaders, both the train and test data need to be normalised for the model to train. The data are normalised using the lower and upper percentiles that we calculated above and will use whilst creating each dataset. The below function defines a Min-Max normalisation with the lower and upper bounds being the lower and upper percentiles, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1022dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalise(data, lower, upper):\n",
    "    return ((data - lower)/ (upper - lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b646e",
   "metadata": {},
   "source": [
    "To extract actual predictions from the network and not data that have been normalised, we will have to inverse this normalisation. The following function is the rearranged equation of the normalisation function we have used above. We will use this after training/testing the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1f4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inverse(data, lower, upper):\n",
    "    return (data * (upper - lower) + lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e30d1",
   "metadata": {},
   "source": [
    "#### Dataset and Dataloaders ####\n",
    "Here we create the dataset for our model. First, the data must be transformed to the correct size for the model (256x256). We do this because the network will take relatively small kernels sizes (of size $4\\times4$) meaning that it has a small receptive field. Taking too large an image size will result in a narrow network which is difficult to train Additionally, the layers within the U-Net are easier to design when the images are a factor of 2 in size, thus resizing the inputs to $256=2^8$ allows for easy construction of the convolution layers.\n",
    "\n",
    "The data in each waveband file are read, appended as an input for short wavebands (as a label for long wavebands) and normalised using the above function. Both the inputs and labels are transformed to a tensor of shape [(channel, height, width)] before being resized to 256x256. We then split the dataset into training and testing, using 90% of the data to train and 10% for testing, before creating the dataloaders. \n",
    "\n",
    "To test the network for predicting JWST $LW$ from the Euclid bands, we change the JWST $SW$ inputs in the *__getitem__* method to the Euclid VIS and NISP data. For the NISP data, we stack NISP-H, NISP-Y, NISP-J (RGB) as opposed to the VIS data which we load and stack with NISP-J and NISP-Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c441616",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "# create the dataset which will be split into train and test\n",
    "class FilterDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        ''' path = path to directory containing fits files '''\n",
    "        self.path = path\n",
    "        self.transforms_inputs = torch.nn.Sequential(transforms.Resize((SIZE, SIZE)))\n",
    "                                                     \n",
    "        self.transforms_labels = torch.nn.Sequential(transforms.Resize((SIZE, SIZE)))\n",
    "                                                    \n",
    "        self.f115w_path = path+'F115W/'\n",
    "        self.f150w_path = path+'F150W/'\n",
    "        self.f200w_path = path+'F200W/'\n",
    "        self.f277w_path = path+'F277W/'\n",
    "        self.f356w_path = path+'F356W/'\n",
    "        self.f444w_path = path+'F444W/'\n",
    "        self.VIS_path = path+'VIS/'\n",
    "        self.NISP_J_path = path+'NISP-J/'\n",
    "        self.NISP_Y_path = path+'NISP-Y/'\n",
    "        self.NISP_H_path = path+'NISP-H/'\n",
    "        self.l1 = len(os.listdir(self.f115w_path)) - 1 \n",
    "    \n",
    "    def __len__(self):\n",
    "        # return total number of fits files for the galaxy cutouts consistent\n",
    "        # with the 'idx' in the __getitem__ method\n",
    "        return (self.l1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get the name of the fits file\n",
    "        name = str(idx)+'_lens.fits'\n",
    "        # for each input filter, get each fits file, open and extract the \n",
    "        # first row (only row which is 'SCI' data) and normalise before\n",
    "        # formatting into an array\n",
    "        hdu1 = fits.open(self.f115w_path+name)[0]\n",
    "        data1 = Normalise(hdu1.data, f115w_lower, f115w_upper)\n",
    "        hdu2 = fits.open(self.f150w_path+name)[0]\n",
    "        data2 = Normalise(hdu2.data, f150w_lower, f150w_upper)\n",
    "        hdu3 = fits.open(self.f200w_path+name)[0]\n",
    "        data3 = Normalise(hdu3.data, f200w_lower, f200w_upper)\n",
    "        # now the same for the label filters as    \n",
    "        hdu4 = fits.open(self.f277w_path+name)[0]\n",
    "        data4 = Normalise(hdu4.data, f277w_lower, f277w_upper)\n",
    "        hdu5 = fits.open(self.f356w_path+name)[0]\n",
    "        data5 = Normalise(hdu5.data, f356w_lower, f356w_upper)\n",
    "        hdu6 = fits.open(self.f444w_path+name)[0]\n",
    "        data6 = Normalise(hdu6.data, f444w_lower, f444w_upper)\n",
    "        # now for the Euclid data - load this is when you need it\n",
    "        #hdu_vis = fits.open(self.VIS_path+name)[0]\n",
    "        #data_vis = Normalise(hdu_vis.data, f115w_lower, f115w_upper)\n",
    "        #hdu_J = fits.open(self.NISP_J_path+name)[0]\n",
    "        #data_J = Normalise(hdu_J.data, f150w_lower, f150w_upper)\n",
    "        #hdu_Y = fits.open(self.NISP_Y_path+name)[0]\n",
    "        #data_Y = Normalise(hdu_Y.data, f115w_lower, f115w_upper)\n",
    "        #hdu_H = fits.open(self.NISP_H_path+name)[0]\n",
    "        #data_H = Normalise(hdu_H.data, f200w_lower, f200w_upper)\n",
    "        \n",
    "        # stack the input filters (f115w, f150w, f200w)\n",
    "        # change this for VIS and NISP bands in the same manner as below\n",
    "        inputs = np.dstack((data1, data2, data3)).astype(\"float32\")\n",
    "        # reformat the inputs as tensors\n",
    "        inputs = transforms.ToTensor()(inputs)\n",
    "        # reshape the tensor to [C, H, W] for the transform to work\n",
    "        inputs = inputs.permute(0, 1, 2)\n",
    "        # now resize the inputs to 256x256\n",
    "        inputs = self.transforms_inputs(inputs)\n",
    "        \n",
    "        # do the same for the labels\n",
    "        labels = np.dstack((data4, data5, data6)).astype(\"float32\")\n",
    "        labels = transforms.ToTensor()(labels)\n",
    "        labels = labels.permute(0, 1, 2)\n",
    "        labels = self.transforms_labels(labels)\n",
    "        \n",
    "        # return the inputs with corresponding labels in a dictionary\n",
    "        return {'Inputs': inputs, 'Labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba3e9367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.FilterDataset object at 0x1297235e0>\n"
     ]
    }
   ],
   "source": [
    "dataset = FilterDataset(path=home)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c674eaba",
   "metadata": {},
   "source": [
    "Now, we create the dataloaders, namely *trainloader* and *testloader*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b89c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the generated dataset into training and testing \n",
    "BATCH_SIZE = 16                                     # set the batch size\n",
    "VALIDATION_SPLIT = 0.1                              # set the validation split of 10%\n",
    "SHUFFLE_DATASET = True                              # shuffle the training data only\n",
    "RANDOM_SEED = 42                                    # randomly shuffle through indexed dataset\n",
    "\n",
    "# create indices for training and test split\n",
    "DATASET_SIZE = len(dataset)\n",
    "# list the dataset with an index for each entry\n",
    "indices = list(range(DATASET_SIZE))\n",
    "# define the split for the dataset\n",
    "split = int(np.floor(DATASET_SIZE * VALIDATION_SPLIT))\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "# split the dataset into training and testing \n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "# create data samplers and dataloaders\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "# create dataloaders\n",
    "trainloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "testloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "#print(len(trainloader), len(testloader)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f501e3",
   "metadata": {},
   "source": [
    "Let's check the shape of the inputs and labels. They must be 3 channels and $256\\times256$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "260f910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 256, 256]) torch.Size([16, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(trainloader))\n",
    "inputs_, labels_ = data['Inputs'], data['Labels']\n",
    "print(inputs_.shape, labels_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf7fc3",
   "metadata": {},
   "source": [
    "#### Generator Architecture ####\n",
    "The following code implements a U-Net to be used as the Generator for the cGAN. It produces the U-Net from the middle part, down in the U shape, and adds down-sampling and up-sampling modules to the left and the right of the middle module, respectively, at every iteration until it reaches the input module and output module:\n",
    "\\\n",
    "![U-Net](images/U-Net.png).\n",
    "\\\n",
    "The blue boxes show the order in which the related modules are built. The U-Net shown in the following code has more layers than depicted above. In the code, we go 8 layers down, so, starting with a 256x256 input, we will get a 1x1 (256/2⁸) image in the middle of the U-Net which then gets up-sampled to produce a 256x256 image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa3e169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net module\n",
    "class UnetBlock(nn.Module):\n",
    "    ''' U-Net is used as the generator of the GAN.\n",
    "        Creates the U-Net from the middle part down and adds down-sampling and\n",
    "        up-sampling modules to the left and right of the middle module.\n",
    "        8 layers down so start with a 256x256 tensor with 3 channels, down-sample \n",
    "        to a 1x1 tensor, then up-sample to a 256x256 tensor with 3 channels. '''\n",
    "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
    "                 innermost=False, outermost=False):\n",
    "        ''' ni = number of filters in the inner convolution layer\n",
    "            nf = number of filters in the outer convolution layer\n",
    "            input_c = number of input channels (= 3)\n",
    "            submodule = previously defined submodules\n",
    "            dropout = not using dropout layers '''\n",
    "        super().__init__()\n",
    "        self.outermost = outermost\n",
    "        if input_c is None: input_c = nf\n",
    "        downconv = nn.Conv2d(in_channels=input_c, out_channels=ni, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = nn.BatchNorm2d(ni)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = nn.BatchNorm2d(nf)\n",
    "        \n",
    "        if outermost: # if this module is the outermost module i.e downsampling\n",
    "            upconv = nn.ConvTranspose2d(in_channels=ni*2, out_channels=nf, kernel_size=4, stride=2, padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost: # if this module is the innermost module, i.e upsampling\n",
    "            upconv = nn.ConvTranspose2d(in_channels=ni, out_channels=nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(in_channels=ni*2, out_channels=nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            if dropout: up += [nn.Dropout(0.5)]\n",
    "            model = down + [submodule] + up\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else: # add skip connections\n",
    "            return torch.cat([x, self.model(x)], dim=1)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    ''' U-Net based generator.'''\n",
    "    def __init__(self, input_c=3, output_c=3, n_down=8, num_filters=64):\n",
    "        ''' input_c = number of input channels (= 3)\n",
    "            output_c = number of output channels (= 3)\n",
    "            n_down = number of downsamples: we start with 256x256 and after \n",
    "                                            8 layers, we have a 1x1 tensor at the bottleneck.\n",
    "            num_filters = number of filters in the last convolution layer. '''\n",
    "        super().__init__()\n",
    "        unet_block = UnetBlock(num_filters*8, num_filters*8, innermost=True)\n",
    "        for _ in range(n_down - 5):\n",
    "            # adds intermediate layers with num_filters * 8 filters\n",
    "            unet_block = UnetBlock(num_filters*8, num_filters*8, submodule=unet_block, dropout=True)\n",
    "        out_filters = num_filters*8\n",
    "        for _ in range(3):\n",
    "            # gradually reduce the number of filters to num_filters\n",
    "            unet_block = UnetBlock(out_filters//2, out_filters, submodule=unet_block)\n",
    "            out_filters //= 2\n",
    "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19da054",
   "metadata": {},
   "source": [
    "#### Discriminator Architecture ####\n",
    "The following code describes the architecture of the Discriminator which implements a model by stacking blocks of Convolution - Batch Normalisation - Leaky ReLU to decide whether the input is real or fake. The first and last blocks do *not* use batch normalisation and the last block has *no* activation function (because the activation function will be embedded in the loss function we will use later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dfaf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a Patch-Discriminator\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    ''' Patch discriminator stacks blocks of convolution-batchnorm-leakyrelu \n",
    "        to decide whether the input tensor is real or fake. \n",
    "        Patch discriminator outputs one number for every NxN pixels of the input\n",
    "        and decides whether each \"patch\" is real/fake. \n",
    "        Patches will be 70 by 70. '''\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        ''' input_c = number of input channels (= 3)\n",
    "            num_filters = number of filters in last convolution layer\n",
    "            n_down = number of layers '''\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        # use if statement to take care of not using a stride of 2 in the last block of the loop\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i+1), s=1 if i == (n_down-1) else 2) for i in range(n_down)]\n",
    "        # do not use normalisation or activation for the last layer of the model\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 3, s=1, norm=False, act=False)] # ouput 3 channel prediction\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    # make a separate method for the repetitive layers\n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n",
    "        ''' norm = batch norm layer\n",
    "        act = apply activation '''\n",
    "        layers = [nn.Conv2d(in_channels=ni, out_channels=nf, kernel_size=k, stride=s, padding=p, bias=not norm)]\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61293e2c",
   "metadata": {},
   "source": [
    "Let's take a look at its blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a792060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchDiscriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(512, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PatchDiscriminator(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88027706",
   "metadata": {},
   "source": [
    "And the shape of its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2acf5fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 30, 30])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = PatchDiscriminator(3)\n",
    "input_ = torch.randn(16, 3, 256, 256) # [Batch, Channels, Height, Width]\n",
    "output = discriminator(input_)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa370df",
   "metadata": {},
   "source": [
    "Notice that we are using a Patch Discriminator. What is a Patch Discriminator?\n",
    "\\\n",
    "In a vanilla discriminator, the model outputs one number (a scalar), which represents how much the model thinks the input is real (or fake). In a patch discriminator, the model outputs one number for every patch of ~70x70 pixels of the input and for each of them, decides whether it is real (or fake), separately. Using such a model for this task is reasonable because the local changes that the model needs to make are important. Making a decision on the whole input regarding whether it is real or fake, as in a vanilla discriminator, cannot take care of the subtleties of this task. \n",
    "\n",
    "Here, the model's output shape is 30x30 but that does not mean that the patches are of size 30x30. The actual patch size is obtained when we compute the [_**receptive field**_](https://www.researchgate.net/figure/The-PatchGAN-discriminator-where-the-receptive-field-of-the-discriminator-is-N-N-Gz_fig5_336431839) of each of these 900 (30x30=900) output numbers, which will be 70 by 70 in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a617e",
   "metadata": {},
   "source": [
    "#### GAN Loss ####\n",
    "We need to initiate the adversarial GAN loss for the final model. Below, in the **init** function, we decide what type of loss we will use (\"vanilla\") and we register some constant tensors as the \"real\" and \"fake\" labels, representing a tensor of all 1's or all 0's, respectively. It fills these tensors when we call the module and computes the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83efd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique loss function for the GAN \n",
    "class GANLoss(nn.Module):\n",
    "    ''' Calculates the GAN loss of the final model.\n",
    "        Uses a \"vanilla\" loss and registers constant tensors for the real\n",
    "        and fake labels. Returns tensors full of zeros or ones to compute the loss'''\n",
    "        \n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer(name='real_label', tensor=torch.tensor(real_label))\n",
    "        self.register_buffer(name='fake_label', tensor=torch.tensor(fake_label))\n",
    "        if gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss() # binary cross entropy loss\n",
    "        elif gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss() \n",
    "        \n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds) # expand to the same size as predictions\n",
    "    \n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f23701",
   "metadata": {},
   "source": [
    "#### Model Initialisation ####\n",
    "Here, we initialise the weights of the model with a mean, $µ=0$, and a standard deviation, $σ=0.02$. We also initialise the entire model by sending to model to the device (I'm using \"cuda\" but you can choose which device you wish to use) and initialising its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7968a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilise the weights of the model here\n",
    "def Init_Weights(net, init='norm', gain=.02):\n",
    "    ''' Image-to-image translation paper state that the model is initialised \n",
    "        with a mean of 0.0 and std 0.02'''\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                # fills tensor with values drawn from normal distribution N(mean,std^2)\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier': \n",
    "                # fills input tensor with avlues sampled from N(0,std^2)\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == 'kaiming': \n",
    "                # resulting tensor has values sampled from N(0,std^2)\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            \n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(tensor=m.bias.data, val=0.0) # tensor filled with zeros\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1.0, gain)\n",
    "            nn.init.constant_(tensor=m.bias.data, val=0.0)\n",
    "    \n",
    "    net.apply(init_func)\n",
    "    print(f\"model initialised with {init} initialisation\")\n",
    "    return net\n",
    "\n",
    "def Init_Model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = Init_Weights(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96720fd",
   "metadata": {},
   "source": [
    "#### The Model ####\n",
    "The following code is a class that brings all the previous sections together and implements the methods required to train the model.\n",
    "\n",
    "Firstly, in the **init** function, we define the Generator and Discriminator networks using the above classes that we defined and we initialise them using the **Init_Model** function above. We define the two loss functions that we have discussed and the optimisers of both the Generator and Discriminator (we use the [_**Adam**_](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimiser which is similar to applying the Gradient Descent Method). It is also worth noting the learning rate of both the Generator and Discriminator, which have a learning rate of *lr_G=lr_D=0.0002*. This learning rate is carefully selected; a learning rate that is too large might lead to a divergent solution, and a learning rate that is too small will take unneccessarily long and eventually end up in a local minimum. A learning rate of *0.0002* is sufficient.\n",
    "\n",
    "The majority of the computations are done in the **optimise** method of this class. First, and only once per iteration (batch of the training set), we call the module's forward method and store the outputs in the *fake_fits* variable of the class. \n",
    "\n",
    "The Discriminator is trained first using the **backward_D** method, where we feed the *fake* data produced by the Generator to the Discriminator (we detach them from the Generator's graph to make sure they act as a constant to the Discriminator) and label the data as *fake*. A batch of *real* data from the training set is then fed to the Discriminator and labelled as *real*. The losses for the *fake* and *real* data is calculated and added togther, the average between the two taken, and the backward method called on the final loss. The Generator is then trained. In the **backward_G** method, the Discriminator is fed the *fake* data and we try to fool the Discriminator by assigning *real* labels and calculating the adversarial (GAN) loss. As previously mentioned, the L1 loss is also used to compute the distance between the predicted output and the target output, which is then multipled by the coefficient *λ* (where we have set λ=100) to balance the two losses before adding this loss to the adversarial loss. \n",
    "\n",
    "The backward method of the loss is finally called. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42262dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to initialise the main GAN network\n",
    "class GANModel(nn.Module):\n",
    "    ''' Initialises the model defining the generator and discriminator in the\n",
    "        __init__ function using the functions given and initialises the loss\n",
    "        functions '''\n",
    "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, beta1=.5, beta2=.999, lambda_L1=100.): \n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "        \n",
    "        if net_G is None:\n",
    "            self.net_G = Init_Model(Unet(input_c=3, output_c=3, n_down=8, num_filters=64), self.device)\n",
    "        else:\n",
    "            self.net_G.to(self.device)\n",
    "        \n",
    "        self.net_D = Init_Model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
    "        self.GAN_loss = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1_loss = nn.L1Loss()\n",
    "        # initialise optimisers for generator and discriminator  \n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1,beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1,beta2))\n",
    "        # initialise empty lists to append the generator and discriminator losses to\n",
    "        self.generator_losses, self.discriminator_losses = [], []\n",
    "    \n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "        \n",
    "    def setup_input(self, data):\n",
    "        # Get the input data and labels\n",
    "        self.inputs = data['Inputs'].to(self.device)\n",
    "        self.labels = data['Labels'].to(self.device)\n",
    "    \n",
    "    def forward(self):\n",
    "        # For each batch in the training set, forward method is called and\n",
    "        # outputs stored in fake_fits variable\n",
    "        self.fake_fits = self.net_G(self.inputs)\n",
    "        \n",
    "    def backward_D(self):\n",
    "        ''' Discriminator loss takes both target and input images.\n",
    "            loss_D_real is sigmoid cross-entropy loss of the target tensors and an array\n",
    "            of ones. \n",
    "            loss_D_fake is sigmoid cross-entropy loss of the input tensors and an\n",
    "            array of zeros.\n",
    "            Discriminator loss is loss_D = loss_D_real + loss_D_fake. '''\n",
    "        # Train the discriminator by feeding the fake images produced by the \n",
    "        # generator \n",
    "        fake_fits = self.fake_fits\n",
    "        fake_preds = self.net_D(fake_fits.detach()) # detach from generator's graph so they act like constants\n",
    "        # label the fake images as fake \n",
    "        self.loss_D_fake = self.GAN_loss(preds=fake_preds, target_is_real=False)\n",
    "        # Now feed a batch of real images from the training set and label them as real\n",
    "        real_fits = self.labels\n",
    "        real_preds = self.net_D(real_fits)\n",
    "        self.loss_D_real = self.GAN_loss(preds=real_preds, target_is_real=True)\n",
    "        # Add the two losses for fake and real, take the average and call backward()\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * .5\n",
    "        self.loss_D.backward()\n",
    "        self.discriminator_losses += [self.loss_D.item()]\n",
    "    \n",
    "    def backward_G(self):\n",
    "        ''' Generator loss is a sigmoid cross-entropy of input tensors and an \n",
    "            array of ones. Using the L1 loss, input tensors are structurally\n",
    "            similar to the target tensors.\n",
    "            Generator loss is defined as loss_G = loss_G_GAN + loss_G_L1*lambda_L1. '''\n",
    "        # Train the generator by feeding the discriminator the fake fits data and \n",
    "        # fool it by assigning real labels and calculating adversarial loss.\n",
    "        fake_fits = self.fake_fits\n",
    "        fake_preds = self.net_D(fake_fits.detach())\n",
    "        self.loss_G_GAN = self.GAN_loss(preds=fake_preds, target_is_real=True)\n",
    "        # Use L1 loss so tensors are not averaged over and compute the \n",
    "        # difference between the prediction and real and multiply \n",
    "        # by constant lambda \n",
    "        self.loss_G_L1 = self.L1_loss(self.fake_fits, self.labels) * self.lambda_L1\n",
    "        # Add L1 loss to the adversarial loss then call backward()\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "        self.generator_losses += [self.loss_G_GAN.item()]\n",
    "        \n",
    "    def optimise(self):\n",
    "        # Now optimise by the usual method of zeroing the gradients and calling\n",
    "        # step() on the optimiser\n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "        \n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dfa51f",
   "metadata": {},
   "source": [
    "#### Helper Functions ####\n",
    "Below are the functions used to help visualise how the losses of the model are updated and to illustrate the performance of the model. The losses are logged and the results are shown with the help of these useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f00318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "    \n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def Create_Loss_Meters():\n",
    "    loss_D_fake = AverageMeter()\n",
    "    loss_D_real = AverageMeter()\n",
    "    loss_D = AverageMeter()\n",
    "    loss_G_GAN = AverageMeter()\n",
    "    loss_G_L1 = AverageMeter()\n",
    "    loss_G = AverageMeter()\n",
    "    \n",
    "    return {'loss_D_fake': loss_D_fake,\n",
    "            'loss_D_real': loss_D_real,\n",
    "            'loss_D': loss_D,\n",
    "            'loss_G_GAN': loss_G_GAN,\n",
    "            'loss_G_L1': loss_G_L1,\n",
    "            'loss_G': loss_G}\n",
    "\n",
    "# Update losses after each epoch\n",
    "def Update_Losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name)\n",
    "        loss_meter.update(loss.item(), count=count)\n",
    "    return loss_meter \n",
    "\n",
    "# Plot the losses for both the Generator and Discriminator\n",
    "def Loss_Plot(model, save=False):\n",
    "    gen_loss = model.generator_losses\n",
    "    dis_loss = model.discriminator_losses\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.plot(gen_loss, label='Generator Loss', color='red')\n",
    "    plt.plot(dis_loss, label='Discriminator Loss', color='blue', linestyle='--')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(f\"loss_{time.time()}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae54aa7",
   "metadata": {},
   "source": [
    "Also plots for plotting the output of the cGAN as opposed to the true label and the input to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d40bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualise_Train(model, data, save=False):\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    model.net_G.train()\n",
    "    fake_fits = model.fake_fits.detach()\n",
    "    fake_fits /= torch.max(fake_fits)\n",
    "    real_fits = model.labels\n",
    "    real_fits /= torch.max(real_fits)\n",
    "    inputs = model.inputs\n",
    "    inputs /= torch.max(inputs)\n",
    "    inputs = inputs.permute(0, 3, 2, 1)\n",
    "    fake_fits = fake_fits.permute(0, 3, 2, 1)\n",
    "    real_fits = real_fits.permute(0, 3, 2, 1)\n",
    "    fig = plt.figure(figsize=(9,11))\n",
    "    for i in range(2):\n",
    "        ax = plt.subplot(3, 2, i+1)\n",
    "        try:\n",
    "            ax.imshow(inputs[i])\n",
    "            ax.set_title(r\"SW Channel [$0.6-2.3\\mu$m]\")\n",
    "            ax.axis(\"off\")\n",
    "        except IndexError:\n",
    "            continue\n",
    "        ax = plt.subplot(3, 2, i+1+2)\n",
    "        ax.imshow(fake_fits[i])\n",
    "        ax.set_title(\"Generated LW\")\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 2, i+1+4)\n",
    "        ax.imshow(real_fits[i])\n",
    "        ax.set_title(r\"Actual LW Channel [$2.4-5.0\\mu$m]\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(\"train.png\")\n",
    "\n",
    "def Visualise_Test(model, data, save=False):\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    model.eval()\n",
    "    fake_fits = model.fake_fits.detach()\n",
    "    fake_fits /= torch.max(fake_fits)\n",
    "    real_fits = model.labels\n",
    "    inputs = model.inputs\n",
    "    inputs /= torch.max(inputs)\n",
    "    inputs = inputs.permute(0, 3, 2, 1)\n",
    "    fake_fits = fake_fits.permute(0, 3, 2, 1)\n",
    "    real_fits = real_fits.permute(0, 3, 2, 1)\n",
    "    real_fits /= torch.max(real_fits)\n",
    "    fig = plt.figure(figsize=(9,11))\n",
    "    for i in range(2):\n",
    "        ax = plt.subplot(3, 2, i+1)\n",
    "        try:\n",
    "            ax.imshow(inputs[i])\n",
    "            ax.set_title(r\"SW Channel [$0.6-2.3\\mu$m]\")\n",
    "            ax.axis(\"off\")\n",
    "        except IndexError:\n",
    "            continue\n",
    "        ax = plt.subplot(3, 2, i+1+2)\n",
    "        ax.imshow(fake_fits[i])\n",
    "        ax.set_title(\"Generated LW\")\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 2, i+1+4)\n",
    "        ax.imshow(real_fits[i])\n",
    "        ax.set_title(r\"Actual LW Channel [$2.4-5.0\\mu$m]\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(\"test2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c90a22",
   "metadata": {},
   "source": [
    "#### Training Function ####\n",
    "The functions below train and test the network, respectively, feeding data from the training set (test set) for the network to learn features from. Here, we set the number of epochs for training. Training with 100 epochs is a recommendation, although, we already see results after 40 epochs. After each epoch, the weights are tuned further to the optimal weight for better model performance.\n",
    "\n",
    "\n",
    "We've also defined a function to log the loss results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe6b4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log_Results(loss_meter_dict):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")\n",
    "        \n",
    "# now train the network, display epochs and losses\n",
    "def Train_Model(model, trainloader, epochs, display_every=30):\n",
    "    print(\"Starting training....\")\n",
    "    start = time.time()\n",
    "    data = next(iter(trainloader)) # batch for visualising the model output after fixed intervals after training\n",
    "    for e in range(epochs):\n",
    "        # function returning a dictionary of objects to log the losses of the complete network\n",
    "        loss_meter_dict = Create_Loss_Meters() \n",
    "        i = 0\n",
    "        for data in tqdm(trainloader):\n",
    "            model.setup_input(data)\n",
    "            model.optimise()\n",
    "            Update_Losses(model, loss_meter_dict, count=data['Inputs'].size(0)) # updates the log objects\n",
    "            i += 1\n",
    "        print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "        if i % display_every == 0: \n",
    "            print(f\"Iteration {i}/{len(trainloader)}\")\n",
    "        total_loss = Log_Results(loss_meter_dict) # function prints out the losses\n",
    "        print(total_loss)\n",
    "    Loss_Plot(model, save=False)\n",
    "    Accuracy_Plot(model, save=False)\n",
    "    Visualise_Train(model, data)\n",
    "    endtime = time.time()\n",
    "    end = endtime - start\n",
    "    print(\"Time to train network: {:.2f}s\".format(end))\n",
    "\n",
    "def Test_Model(model, testloader, epochs, display_every=30):\n",
    "    print(\"Testing...\")\n",
    "    data = next(iter(testloader))\n",
    "    for epoch in range(epochs):\n",
    "        loss_meter_dict = Create_Loss_Meters()\n",
    "        counter = 0\n",
    "        for data in tqdm(testloader):\n",
    "            model.setup_input(data)\n",
    "            model.optimise()\n",
    "            Update_Losses(model, loss_meter_dict, count=data['Inputs'].size(0))\n",
    "            counter += 1\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        if counter % display_every == 0:\n",
    "            print(f\"Iteration {counter}/{len(testloader)}\")\n",
    "        total_loss = Log_Results(loss_meter_dict)\n",
    "        print(total_loss)\n",
    "    Loss_Plot(model, save=False)\n",
    "    Accuracy_Plot(model, save=False)\n",
    "    Visualise_Test(model, data)\n",
    "    print(\"Finished testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040600d5",
   "metadata": {},
   "source": [
    "Each epoch takes between 3 to 4 minutes on a powerful GPU. The above code can be altered to test the model on the test set by setting the model to evaluation mode. An example of training the model is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdaa7233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialised with norm initialisation\n",
      "model initialised with norm initialisation\n"
     ]
    }
   ],
   "source": [
    "model = GANModel()\n",
    "#Train_Model(model, trainloader, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a987071",
   "metadata": {},
   "source": [
    "### Results ###\n",
    "After training the cGAN for 100 epochs, the test set is used (the *Visualise_Test()* function) with 40 epochs to measure network performance. Below we see an output on the test set in the first plot. The plot below shows the input, generated data and true label for each individual NIRcam filter. \n",
    "\n",
    "![output3](images/Output3.png)\n",
    "\n",
    "\n",
    "![bands output](images/Bands-Output.png)\n",
    "\n",
    "As we can see, the model has understanding of the features in the data and some colourisation. It can clearly predict the lenses as seen in the $LW$ filters to a high accuracy, noting almost zero difference between the output and the true label. We are seeing the clear, visible arcs/rings/mulitple images and the lensing galaxy. Although, we must see that the model is learning features such as a mostly black background.\n",
    "Nevertheless, the model is a good baseline model for predicting longer wavebands and can be further implemented to predict lenses in unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73cb3f",
   "metadata": {},
   "source": [
    "### Euclid VIS to JWST NIRcam LW\n",
    "Predicting $LW$ JWST NIRcam data given Euclid-VIS or Euclid-NISP data or a mixture of both would be a beneficial application of the cGAN. Now, the pixel resolution between the two Euclid instruments and JWST NIRcam is different, so we must expect a different output from before. It could be the case that predicting strong gravitational lenses as observed by JWST given the observation by Euclid is a method of anomaly detection- observations made by Euclid that are potential gravitational lenses could be proved as non-lenses as observed by JWST. Although this does not solve the problem of finding strong gravitational lenses, it is useful for improving the purity and recal of our strong lens finding methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04968f18",
   "metadata": {},
   "source": [
    "Below shows the output from the cGAN by testing on the test set when recreating the dataloaders in *FilterDataset* with the stacked Euclid VIS data:\n",
    "\n",
    "![Results VIS](images/VIS_Output1.png)\n",
    "\n",
    "Additionally, we can further explore the result by plotting the individual results from each filter with the difference image between the $LW$ prediction of a particular lens in the figure above and the true $LW$ of that lens shown below:\n",
    "\n",
    "![bands output vis](images/Wavebands_VIS1.png)\n",
    "\n",
    "In both plots, we see that the JWST NIRcam $LW$ output is much more resolved than the Euclid VIS input- unexpected since we are getting more information from the lenses as observed by JWST. Thus the cGAN is capable or interpreting the Euclid information and transversing that to a JWST pixel resolution. For reference, we provide the residual between the cGAN's prediction and the ground truth JWST $LW$:\n",
    "\n",
    "![residual VIS](images/Residual_VIS.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7fb6b",
   "metadata": {},
   "source": [
    "Interestingly, again, we see similar results by predicting JWST NIRcam $LW$ information of the strong gravitational lenses with Euclid NISP information as input to the network. This is done in the same process as above by changing the input information to that of Euclid NISP in the *FilterDataset* class.\n",
    "\n",
    "![results nisp](images/NISP_Output1.png)\n",
    "\n",
    "Again, we can visualise the prediction of each individual JWST NIRcam $LW$ filter.\n",
    "\n",
    "![nisp bands](images/Wavebands_NISP111.png)\n",
    "\n",
    "with the residual between the prediction by the cGAN and the ground truth JWST data shown below:\n",
    "\n",
    "![residual nisp](images/Residual_NISP1.png)\n",
    "\n",
    "For more results as those shown above with each individual filter prediction, see the *images/* folder in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00cca19",
   "metadata": {},
   "source": [
    "### Improved Purity and Recall\n",
    "The below example shows a clear, red ring observed in the Euclid NISP band. This has an Einstein radius of $\\approx 1.8\"$. Both the prediction by the cGAN and the true JWST NIRcam $LW$ data show no such ring at all:\n",
    "\n",
    "![anomaly](images/Anomaly.png)\n",
    "\n",
    "To further visualise each individual band, we can plot both the prediction by the cGAN and the true information in each individual filter:\n",
    "\n",
    "![anomaly bands](images/Anomaly_Bands.png)\n",
    "\n",
    "Again, we see no such ring in any JWST NIRcam $LW$ filter, in either prediction or true label.\n",
    "Although this is of no result of the cGAN, we can clearly see that a lens observed by Euclid is not observed by JWST. Again this not not aid in solving the problem of lens finding, but there is clear proof that this particular example is a potential non-lens. This could improve purity of our sample lenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e18eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-gpu]",
   "language": "python",
   "name": "conda-env-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
